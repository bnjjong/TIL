# 📘 제7장 — 신뢰성 있는 데이터 전달


## 🧩 7.1 신뢰성 보장 (Guarantees)

### 📍 핵심 요약

* **신뢰성(reliability)** 은 단일 구성요소가 아닌 **시스템 전체의 속성**임.
* Kafka는 **트레이드오프 가능한 신뢰성 모델**을 제공함.
* 운영자, 개발자, 인프라 엔지니어 모두의 책임.

### ⚙️ Kafka의 핵심 보장

| 항목              | 보장 내용                                             |
| --------------- | ------------------------------------------------- |
| 메시지 순서          | 파티션 내 순서 보장 (`A → B` 순서로 쓰면 동일 프로듀서 기준 동일 순서로 읽힘) |
| 커밋(Commit)      | 모든 인싱크 레플리카(ISR)에 기록된 후 커밋됨                       |
| 내구성(Durability) | 최소 1개 레플리카가 살아있는 한 커밋된 메시지는 유실되지 않음               |
| 컨슈머             | 커밋된 메시지만 읽음                                       |

> 💡 Kafka의 신뢰성은 완벽하지 않다 —
> ‘가용성 vs 일관성’의 트레이드오프를 설정에 따라 조절 가능.

---

## 🔁 7.2 복제 (Replication)

### 📍 구조 요약

* 각 **토픽 = 여러 파티션**으로 구성
* 각 **파티션 = 여러 레플리카(replica)** 로 구성
* 하나는 **리더(Leader)**, 나머지는 **팔로워(Follower)**

### 🧠 인싱크 레플리카(ISR)

* 다음 조건을 모두 만족해야 인싱크 상태:

    1. 주키퍼와의 세션 활성 (기본 6~18초 내 하트비트)
    2. 최근 10~30초 내 리더로부터 메시지를 정상적으로 읽음
    3. 복제 지연(lag)이 설정값 이하

> 💡 ISR 수가 적어질수록 → 처리속도는 빨라지지만
> 내구성과 장애 복구 능력은 낮아짐.

---

## ⚙️ 7.3 브로커 설정 (Broker-Level Reliability)

Kafka 신뢰성의 근간은 **복제 팩터 / 리더 선출 정책 / 인싱크 레플리카 관리 / 디스크 플러시 정책**임.

---

### 7.3.1 복제 팩터 (Replication Factor)

| 항목                           | 설명            |
| ---------------------------- | ------------- |
| `replication.factor`         | 토픽별 복제 개수     |
| `default.replication.factor` | 자동 생성 토픽의 기본값 |
| 일반값                          | 3 (추천)        |

#### 📊 트레이드오프

| 요인          | 영향                     |
| ----------- | ---------------------- |
| 가용성         | 높을수록 안정                |
| 내구성         | 복제본이 많을수록 안전           |
| 처리량         | 낮을수록 빠름                |
| 비용          | 높을수록 비쌈                |
| 지연(latency) | 높을수록 일부 브로커가 느릴 가능성 증가 |

> ⚠️ 랙 단위 장애 대비:
> `broker.rack` 설정으로 다른 랙/가용영역에 분산 저장 권장.

---

### 7.3.2 언클린 리더 선출 (Unclean Leader Election)

| 설정                               | 설명                       |
| -------------------------------- | ------------------------ |
| `unclean.leader.election.enable` | 아웃오브싱크 레플리카를 리더로 허용할지 여부 |
| 기본값                              | `false` (가장 안전)          |

#### 📉 트레이드오프

| 선택      | 장점        | 단점           |
| ------- | --------- | ------------ |
| `true`  | 가용성 ↑     | 데이터 유실 가능    |
| `false` | 데이터 무결성 ↑ | 복구 전까지 읽기 불가 |

> 💡 일반적으로 `false` 권장.
> 단, 긴급 복구 시 `true`로 일시 변경 후 복구 후 다시 `false`.

---

### 7.3.3 최소 인싱크 레플리카 (min.insync.replicas)

| 설정                    | 설명                |
| --------------------- | ----------------- |
| `min.insync.replicas` | 커밋 시 필요한 최소 ISR 수 |
| 기본값                   | 1                 |
| 권장값                   | 복제 팩터 3일 때 최소 2   |

> 💡 `acks=all` + `min.insync.replicas=2` →
> 리더+팔로워 최소 2곳에 저장되어야 커밋 완료.

---

### 7.3.4 레플리카 ISR 유지 (Replica Lag Settings)

| 설정                             | 설명                      | 기본값      |
| ------------------------------ | ----------------------- | -------- |
| `zookeeper.session.timeout.ms` | 주키퍼 하트비트 타임아웃           | 18,000ms |
| `replica.lag.time.max.ms`      | 리더로부터 메시지를 못 받은 최대 허용시간 | 30,000ms |

---

### 7.3.5 디스크 저장 (Flush Policy)

| 설정               | 설명                 |
| ---------------- | ------------------ |
| `flush.messages` | 디스크 플러시 전 최대 메시지 수 |
| `flush.ms`       | 디스크 플러시 주기(ms)     |

> 💡 기본적으로 Kafka는 OS 페이지 캐시에 의존함.
> 디스크 플러시 빈도를 높이면 신뢰성↑, 처리량↓

---

## ✉️ 7.4 신뢰성 있는 프로듀서 설정

### 7.4.1 Acks 설정 (응답 모드)

| `acks` 값 | 의미              | 신뢰성   | 지연    |
| -------- | --------------- | ----- | ----- |
| `0`      | 네트워크 전송 시 성공 처리 | 매우 낮음 | 매우 빠름 |
| `1`      | 리더에 기록 후 응답     | 중간    | 중간    |
| `all`    | 모든 ISR에 복제 후 응답 | 최고    | 느림    |

> ✅ **추천:** `acks=all` + `enable.idempotence=true`

---

### 7.4.2 프로듀서 재시도 (Retries)

| 설정                    | 설명          | 권장값       |
| --------------------- | ----------- | --------- |
| `retries`             | 재시도 횟수      | `MAX_INT` |
| `delivery.timeout.ms` | 전체 재시도 타임아웃 | 충분히 크게    |
| `enable.idempotence`  | 중복 방지       | `true`    |

> 💡 재시도는 최소 “한 번(at least once)” 보장을 하지만
> 멱등성(idempotence)을 켜면 “정확히 한 번(exactly once)”에 근접 가능.

---

### 7.4.3 추가 에러 처리

* 직렬화 실패, 인증/인가 실패, 타임아웃 등은 애플리케이션 레벨에서 처리 필요.
* “데드레터 큐(Dead Letter Queue)” 패턴 권장:
  실패 메시지를 별도 토픽에 기록 후 재처리.

---

## 🧭 7.5 신뢰성 있는 컨슈머 설정

### 7.5.1 주요 설정

| 설정                        | 설명                                  |
| ------------------------- | ----------------------------------- |
| `group.id`                | 컨슈머 그룹 식별자                          |
| `auto.offset.reset`       | 오프셋 없음 시 동작 (`earliest` / `latest`) |
| `enable.auto.commit`      | 오프셋 자동 커밋 여부                        |
| `auto.commit.interval.ms` | 자동 커밋 주기 (기본 5초)                    |

> ⚠️ 자동 커밋 시 중복/누락 위험 존재.
> 복잡한 처리 로직이 있다면 수동 커밋(`commitSync`) 사용 권장.

---

### 7.5.2 명시적 오프셋 커밋 전략

| 패턴          | 설명               |
| ----------- | ---------------- |
| 처리 후 커밋     | 안전하지만 지연 발생 가능   |
| 주기적 커밋      | 성능 ↑, 재시작 시 중복 ↑ |
| 리밸런스 시 커밋   | 안전한 종료를 위해 필요    |
| 재시도 / 데드레터큐 | 처리 실패 시 별도 토픽으로  |

> 💡 `commitSync()`는 정확성 ↑, `commitAsync()`는 성능 ↑.
> 상황에 맞게 조합 사용.

---

## 🔍 7.6 시스템 신뢰성 검증

Kafka는 단순 설정만으로 신뢰성이 보장되지 않는다.
**테스트 → 검증 → 모니터링** 3단계가 필수다.

---

### 7.6.1 설정 검증 (Configuration Validation)
#### 🎯 목적
Kafka를 실제 서비스에서 사용하기 전에,
- 우리가 설정한 값(acks, retries, delivery.timeout.ms, replication.factor 등)이
올바르게 작동하는지,
- 장애 상황에서도 데이터 손실 없이 정상 복구되는지를
**사전에 검증(테스트)**하기 위한 절입니다.

> 요약하자면:
“Kafka를 운영에 올리기 전에, 진짜 설정이 우리가 기대한 대로 동작하는지 미리 실험해보자.”


#### Kafka가 제공하는 검증 도구

Kafka `org.apache.kafka.tools` 패키지에는 아래 두 도구가 포함되어 있습니다:

| 도구명                    | 역할       | 특징                   |
| ---------------------- | -------- | -------------------- |
| **VerifiableProducer** | 검증용 프로듀서 | 순서대로 숫자가 포함된 메시지를 보냄 |
| **VerifiableConsumer** | 검증용 컨슈머  | 받은 메시지를 순서대로 읽어 검증   |

> 두 도구 모두 CLI(명령행)로 실행할 수 있고,
> 자동화 테스트 프레임워크에서도 사용 가능.

---

## 🧪 3️⃣ 검증용 프로듀서 동작 방식

* 1부터 n까지 **순서대로 숫자가 포함된 메시지를 전송**합니다.
* 일반 프로듀서와 동일하게 `acks`, `retries`, `delivery.timeout.ms` 등의 설정을 사용합니다.
* 각 메시지 전송 결과(성공/에러)를 출력합니다.
* 이걸 통해 “현재 설정이 안정적으로 메시지를 보장하는지” 확인할 수 있습니다.

---

## 🔍 4️⃣ 검증용 컨슈머 동작 방식

* VerifiableProducer가 보낸 메시지를 그대로 읽어옵니다.
* 받은 메시지 순서, 누락 여부, 커밋 상태 등을 검사합니다.
* **프로듀서 → 브로커 → 컨슈머** 전체 체인을 검증하는 셈입니다.

---

## 🧩 5️⃣ 테스트 시나리오 예시

Kafka는 단순히 메시지 전송뿐 아니라, 장애 상황을 일부러 만들어서 테스트해보는 걸 권장합니다.

| 시나리오              | 테스트 내용                       | 확인 포인트               |
| ----------------- | ---------------------------- | -------------------- |
| **리더 선출 테스트**     | 리더 브로커를 강제로 중단시키면?           | 리더 재선출 시간, 메시지 손실 여부 |
| **컨트롤러 재시작 테스트**  | 컨트롤러 브로커를 재시작하면?             | 시스템이 얼마나 빨리 회복되는가    |
| **롤링 재시작 테스트**    | 브로커를 하나씩 순차 재시작              | 메시지 유실 없이 유지되는가      |
| **언클린 리더 선출 테스트** | Out-of-Sync 레플리카를 리더로 선출할 경우 | 메시지 일관성 유지 여부        |

---

## 🧠 6️⃣ 검증 절차 예시

1. **시나리오 선택**
   → 예: “리더 브로커 강제 중단 시 테스트”
2. **VerifiableProducer 실행**
   → 메시지를 연속적으로 송신
3. **VerifiableConsumer 실행**
   → 메시지를 연속적으로 수신 및 검증
4. **장애 유발 (리더 중단, 브로커 재시작 등)**
   → 메시지 유실 여부 확인
5. **결과 비교**
   → 보낸 메시지 수 == 받은 메시지 수라면 설정 검증 성공 ✅

---

## 💻 7️⃣ 실제 테스트 코드 위치

Kafka 오픈소스에는 이런 테스트를 자동으로 돌리는 **테스트 스위트(test suite)**가 포함돼 있습니다.
📁 [GitHub 링크](https://github.com/apache/kafka/tree/trunk/tests)

* 여기서 VerifiableProducer와 VerifiableConsumer를 활용한 다양한 시나리오가 구현되어 있습니다.
* 예: 업그레이드 시 메시지 손실이 없는지, 리더 재선출 후에도 순서 보장이 되는지 등.

---

## 🧾 요약 정리

| 항목     | 설명                                      |
| ------ | --------------------------------------- |
| 목적     | 설정이 실제로 의도대로 동작하는지 확인                   |
| 주요 도구  | VerifiableProducer / VerifiableConsumer |
| 검증 방식  | 순차 메시지 송신 → 장애 유발 → 수신 확인               |
| 주요 테스트 | 리더 선출, 컨트롤러 재시작, 롤링 재시작, 언클린 리더 선출      |
| 결과 판단  | 보낸 메시지 수 == 받은 메시지 수 → 성공               |

---

### 7.6.2 애플리케이션 검증

* 커스텀 에러 처리 / 오프셋 커밋 로직 확인
* `Trogdor` 프레임워크로 네트워크 장애 주입 테스트 가능
* 통합 테스트 시 “예상 동작”과 실제 결과 비교 필수

---

### 7.6.3 프로덕션 모니터링

| 항목    | 지표                                       | 의미               |
| ----- | ---------------------------------------- | ---------------- |
| 프로듀서  | `record-error-rate`, `record-retry-rate` | 전송 실패/재시도율       |
| 컨슈머   | `consumer-lag`                           | 파티션별 읽기 지연       |
| 전송 흐름 | 이벤트 생성→소비 간 타임스탬프 차이                     | end-to-end 지연 측정 |

> 🧠 **Burrow** (by LinkedIn): 컨슈머 랙 모니터링에 적합
> **JMX Metrics** + **Alerting Rule** 조합으로 운영 환경에서 검증

---

## 💻 Kotlin 실무 예제

### As-Is: 단순 Ack=1 프로듀서

```kotlin
val props = Properties().apply {
    put("bootstrap.servers", "localhost:9092")
    put("acks", "1") // 리더만 응답
    put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer")
    put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer")
}
val producer = KafkaProducer<String, String>(props)
producer.send(ProducerRecord("order-topic", "orderId-1", "paymentSuccess"))
```

---

### To-Be: 신뢰성 강화형 (acks=all + 멱등성 + 재시도 + DLQ)

```kotlin
val props = Properties().apply {
    put("bootstrap.servers", "localhost:9092")
    put("acks", "all")
    put("enable.idempotence", "true")
    put("retries", Int.MAX_VALUE.toString())
    put("delivery.timeout.ms", "120000")
    put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer")
    put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer")
}

val producer = KafkaProducer<String, String>(props)

fun sendOrderEvent(orderId: String, payload: String) {
    try {
        producer.send(ProducerRecord("order-topic", orderId, payload)).get()
    } catch (e: Exception) {
        // DLQ로 전송
        producer.send(ProducerRecord("order-dlq", orderId, payload))
    }
}
```

---

### Kotest 예시

```kotlin
class ReliableProducerTest : StringSpec({
    "should send to DLQ when broker fails" {
        val producer = mockk<KafkaProducer<String, String>>(relaxed = true)
        every { producer.send(any()) } throws Exception("Simulated failure")

        val dlqProducer = ReliableProducer(producer)
        dlqProducer.sendOrderEvent("123", "payload")
        verify { producer.send(match { it.topic() == "order-dlq" }) }
    }
})
```

---

## 🧭 전체 요약표

| 범주            | 핵심 내용                                               | 실무 포인트                                 |
| ------------- | --------------------------------------------------- | -------------------------------------- |
| **보장(7.1)**   | 순서, 커밋, 내구성                                         | Kafka는 설정 기반 신뢰성 제공                    |
| **복제(7.2)**   | ISR / 리더-팔로워                                        | lag 관리가 핵심                             |
| **브로커(7.3)**  | replication.factor / min.insync.replicas / flush 정책 | 트레이드오프 조절                              |
| **프로듀서(7.4)** | acks / 재시도 / 멱등성                                    | `acks=all` + `enable.idempotence=true` |
| **컨슈머(7.5)**  | 커밋 전략 / 리밸런스 처리                                     | 자동 커밋 지양, 명시적 커밋 권장                    |
| **검증(7.6)**   | 설정, 코드, 모니터링                                        | Trogdor·Burrow 등으로 지속 테스트              |

---

## 📚 참고 링크

* [KIP-98: Exactly Once Semantics](https://cwiki.apache.org/confluence/display/KAFKA/KIP-98)
* [Kafka Reliability & Idempotence Guide (Confluent)](https://www.confluent.io/blog/transactions-apache-kafka/)
* [LinkedIn Burrow - Consumer Lag Monitoring](https://github.com/linkedin/Burrow)

---
