# ğŸ§© ì œ4ì¥ ì „ì²´ ê°œìš” â€” â€œì¹´í”„ì¹´ ì»¨ìŠˆë¨¸: ì¹´í”„ì¹´ì—ì„œ ë°ì´í„° ì½ê¸°â€

ì´ ì¥ì€ **KafkaConsumer APIì˜ ê°œë…ê³¼ ë™ì‘ ì›ë¦¬, ì„¤ì •, ì˜¤í”„ì…‹ ì»¤ë°‹ ì „ëµ**ì„ ë‹¤ë£¨ë©°,
í”„ë¡œë“€ì„œ(ì“°ê¸°)ì— ëŒ€ì‘ë˜ëŠ” **ì»¨ìŠˆë¨¸(ì½ê¸°)** ì¸¡ì˜ ëª¨ë“  í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## 4.1 ì»¨ìŠˆë¨¸ ê°œë…

### ğŸ“í•µì‹¬ ê°œë… ìš”ì•½

| êµ¬ë¶„                         | ë‚´ìš©                                  |
| -------------------------- | ----------------------------------- |
| **ì»¨ìŠˆë¨¸(Consumer)**          | í† í”½ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ì˜¤ëŠ” Kafka í´ë¼ì´ì–¸íŠ¸          |
| **ì»¨ìŠˆë¨¸ ê·¸ë£¹(Consumer Group)** | ì—¬ëŸ¬ ì»¨ìŠˆë¨¸ê°€ í˜‘ë ¥í•˜ì—¬ í† í”½ íŒŒí‹°ì…˜ì„ ë¶„ì‚° ì²˜ë¦¬í•˜ëŠ” ë‹¨ìœ„     |
| **íŒŒí‹°ì…˜ í• ë‹¹**                 | ê·¸ë£¹ ë‚´ ê° ì»¨ìŠˆë¨¸ê°€ ì„œë¡œ ë‹¤ë¥¸ íŒŒí‹°ì…˜ì„ ë§¡ìŒ           |
| **ë¦¬ë°¸ëŸ°ìŠ¤(Rebalance)**        | ê·¸ë£¹ ë‚´ ì»¨ìŠˆë¨¸ ìˆ˜ë‚˜ í† í”½ íŒŒí‹°ì…˜ êµ¬ì¡°ê°€ ë³€í•  ë•Œ ì¬í• ë‹¹     |
| **ì •ì  ë©¤ë²„ì‹­**                 | ì»¨ìŠˆë¨¸ ì¬ì‹œì‘ ì‹œ ê¸°ì¡´ íŒŒí‹°ì…˜ì„ ìœ ì§€í•˜ì—¬ ë¶ˆí•„ìš”í•œ ë¦¬ë°¸ëŸ°ìŠ¤ ë°©ì§€ |

### âœï¸ ë‚´ ìƒê°

> Kafka ì»¨ìŠˆë¨¸ì˜ **í™•ì¥ì„±ì˜ í•µì‹¬ êµ¬ì¡°**ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.
> ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” **ì •ì  ê·¸ë£¹ ë©¤ë²„ì‹­** ì„¤ì •ì„ í™œìš©í•´ ë¦¬ë°¸ëŸ°ìŠ¤ ë¹„ìš©ì„ ì¤„ì´ëŠ” ê²ƒì´ ì¤‘ìš”.

---

## 4.2 ì»¨ìŠˆë¨¸ ìƒì„±í•˜ê¸°

`KafkaConsumer` ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•  ë•Œ í•„ìˆ˜ ì†ì„±ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

| ì†ì„±                                        | ì„¤ëª…           |
| ----------------------------------------- | ------------ |
| `bootstrap.servers`                       | ë¸Œë¡œì»¤ ì ‘ì† ì •ë³´    |
| `key.deserializer` / `value.deserializer` | ë©”ì‹œì§€ ì—­ì§ë ¬í™” í´ë˜ìŠ¤ |
| `group.id`                                | ì»¨ìŠˆë¨¸ ê·¸ë£¹ ì‹ë³„ì   |

---

## 4.3 í† í”½ êµ¬ë…í•˜ê¸°

ì»¨ìŠˆë¨¸ëŠ” `subscribe()`ë¥¼ í†µí•´ í† í”½ì„ êµ¬ë…í•©ë‹ˆë‹¤.

* íŠ¹ì • í† í”½ ì´ë¦„ ë˜ëŠ” ì •ê·œì‹(`Pattern.compile("test.*")`)ìœ¼ë¡œ êµ¬ë… ê°€ëŠ¥
* ì •ê·œì‹ ì‚¬ìš© ì‹œ, ìƒˆë¡œ ì¶”ê°€ë˜ëŠ” í† í”½ë„ ìë™ í¬í•¨
* ë‹¨, í† í”½/íŒŒí‹°ì…˜ ìˆ˜ê°€ ë§ì„ ë•ŒëŠ” í´ëŸ¬ìŠ¤í„° ë¶€í•˜ ì¦ê°€ì— ì£¼ì˜

---

## 4.4 í´ë§ ë£¨í”„ (poll loop)

ì¹´í”„ì¹´ ì»¨ìŠˆë¨¸ëŠ” **â€œê³„ì† í´ë§í•˜ì§€ ì•Šìœ¼ë©´ ì£½ì€ ê²ƒìœ¼ë¡œ ê°„ì£¼ëœë‹¤.â€**

```java
while (true) {
  val records = consumer.poll(Duration.ofMillis(100))
  for (record in records) {
    println("topic=${record.topic()}, offset=${record.offset()}")
  }
}
```

* `poll()`ì€ ë°ì´í„°ë¥¼ ìš”ì²­í•˜ê³  ì¼ì • ì‹œê°„ ê¸°ë‹¤ë¦¼
* `max.poll.interval.ms` ì´ìƒ í˜¸ì¶œë˜ì§€ ì•Šìœ¼ë©´ ì»¨ìŠˆë¨¸ëŠ” â€œì£½ì€â€ ê²ƒìœ¼ë¡œ íŒë‹¨ë˜ì–´ ë¦¬ë°¸ëŸ°ìŠ¤ ë°œìƒ
* í•˜ë‚˜ì˜ ì»¨ìŠˆë¨¸ ì¸ìŠ¤í„´ìŠ¤ëŠ” í•˜ë‚˜ì˜ ìŠ¤ë ˆë“œì—ì„œë§Œ ì•ˆì „í•˜ê²Œ ì‚¬ìš© ê°€ëŠ¥

### âœï¸ ë‚´ ìƒê°

> â€œí´ë§ ë£¨í”„â€ëŠ” ì¹´í”„ì¹´ ì»¨ìŠˆë¨¸ì˜ ìƒëª…ì„ ì…ë‹ˆë‹¤.
> CPU ë°”ìš´ë“œ/IO ë°”ìš´ë“œ ì‘ì—…ì€ ë³„ë„ ì›Œì»¤ ìŠ¤ë ˆë“œë¡œ ë¶„ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

---

## 4.5 ì»¨ìŠˆë¨¸ ì„¤ì • (Configuration)

### âš™ï¸ ì£¼ìš” ì„±ëŠ¥/ì‹ ë¢°ì„± ê´€ë ¨ ì˜µì…˜ ìš”ì•½

| ì†ì„±                              | ì„¤ëª…                                                                |
| ------------------------------- | ----------------------------------------------------------------- |
| `fetch.min.bytes`               | ìµœì†Œ ë°ì´í„° ì–‘, ë„ˆë¬´ ì‘ìœ¼ë©´ ìš”ì²­ ê³¼ë‹¤ ë°œìƒ                                         |
| `fetch.max.wait.ms`             | ìµœëŒ€ ëŒ€ê¸° ì‹œê°„, fetch.min.bytesì™€ í•¨ê»˜ ì¡°ì •                                  |
| `fetch.max.bytes`               | í•œ ë²ˆì— ë°›ì„ ìµœëŒ€ ë°ì´í„° í¬ê¸°                                                 |
| `session.timeout.ms`            | í•˜íŠ¸ë¹„íŠ¸ ë¯¸ìˆ˜ì‹  ì‹œ ê·¸ë£¹ íƒˆí‡´ê¹Œì§€ì˜ ì‹œê°„                                            |
| `heartbeat.interval.ms`         | í•˜íŠ¸ë¹„íŠ¸ ì „ì†¡ ì£¼ê¸°                                                        |
| `max.poll.records`              | í•œ ë²ˆì˜ pollì—ì„œ ì²˜ë¦¬í•  ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜                                          |
| `auto.offset.reset`             | ìœ íš¨ ì˜¤í”„ì…‹ì´ ì—†ì„ ë•Œ ì‹œì‘ ìœ„ì¹˜(`latest`/`earliest`)                           |
| `enable.auto.commit`            | ìë™ ì»¤ë°‹ ì—¬ë¶€                                                          |
| `partition.assignment.strategy` | íŒŒí‹°ì…˜ ë¶„ë°° ì•Œê³ ë¦¬ì¦˜(`Range`, `RoundRobin`, `Sticky`, `CooperativeSticky`) |

### âœï¸ ë‚´ ìƒê°

> **Sticky + CooperativeSticky** ì¡°í•©ì€ ìµœì‹  Kafka(3.1+)ì—ì„œ ì‚¬ì‹¤ìƒ í‘œì¤€ì…ë‹ˆë‹¤.
> ì•ˆì •ì„±ê³¼ íš¨ìœ¨ì„±ì´ ëª¨ë‘ ê°œì„ ë©ë‹ˆë‹¤.

---

## 4.6 ì˜¤í”„ì…‹ê³¼ ì»¤ë°‹ (Offset & Commit)

| ì»¤ë°‹ ìœ í˜•                               | íŠ¹ì§•                 |
| ----------------------------------- | ------------------ |
| **ìë™ ì»¤ë°‹ (enable.auto.commit=true)** | ê°„ë‹¨í•˜ì§€ë§Œ ì¤‘ë³µ ì²˜ë¦¬ ê°€ëŠ¥ì„± ë†’ìŒ |
| **ìˆ˜ë™ ì»¤ë°‹ (commitSync)**              | ì•ˆì „í•˜ì§€ë§Œ ë¸”ë¡œí‚¹          |
| **ë¹„ë™ê¸° ì»¤ë°‹ (commitAsync)**            | ë¹ ë¥´ì§€ë§Œ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ í•„ìš”   |

**í•µì‹¬ ê°œë…**

* KafkaëŠ” â€œë§ˆì§€ë§‰ìœ¼ë¡œ ì„±ê³µ ì²˜ë¦¬ëœ ì˜¤í”„ì…‹â€ì„ ì»¤ë°‹í•˜ì—¬ **idempotent ì²˜ë¦¬ ë³´ì¥**
* `_consumer_offsets` í† í”½ì— ì €ì¥ë¨
* ì»¤ë°‹ ìœ„ì¹˜ ì˜¤ë¥˜ ì‹œ ì¤‘ë³µ ì²˜ë¦¬(Too low offset) ë˜ëŠ” ìœ ì‹¤(Too high offset) ë°œìƒ ê°€ëŠ¥

## 4.7 ë¦¬ë°¸ëŸ°ìŠ¤ ë¦¬ìŠ¤ë„ˆ (ConsumerRebalanceListener)

### ğŸ“í•µì‹¬ ê°œë…

* ì»¨ìŠˆë¨¸ ê·¸ë£¹ ë‚´ íŒŒí‹°ì…˜ì´ ì¬í• ë‹¹ë  ë•Œ **ì˜¤í”„ì…‹ì„ ì•ˆì „í•˜ê²Œ ì»¤ë°‹**í•˜ê¸° ìœ„í•´ ì‚¬ìš©
* `ConsumerRebalanceListener`ë¥¼ êµ¬í˜„í•˜ë©´
  ë¦¬ë°¸ëŸ°ìŠ¤ ì‹œì (before/after)ì— ì»¤ë°‹/ì´ˆê¸°í™” ì‘ì—… ìˆ˜í–‰ ê°€ëŠ¥

```java
consumer.subscribe(List.of("orders"), new ConsumerRebalanceListener() {
    @Override
    public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
        // ë¦¬ë°¸ëŸ°ìŠ¤ ì§ì „, í˜„ì¬ ì²˜ë¦¬ ì™„ë£Œëœ ì˜¤í”„ì…‹ì„ ì»¤ë°‹
        consumer.commitSync(currentOffsets)
    }

    @Override
    public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
        // ìƒˆ íŒŒí‹°ì…˜ í• ë‹¹ ì‹œ í•„ìš”í•œ ì´ˆê¸°í™” ë¡œì§
    }
});
```

| ë©”ì„œë“œ                    | í˜¸ì¶œ ì‹œì   | ì£¼ìš” ì—­í•          |
| ---------------------- | ------ | ------------- |
| `onPartitionsRevoked`  | ë¦¬ë°¸ëŸ°ìŠ¤ ì „ | ê¸°ì¡´ íŒŒí‹°ì…˜ ì˜¤í”„ì…‹ ì»¤ë°‹ |
| `onPartitionsAssigned` | ë¦¬ë°¸ëŸ°ìŠ¤ í›„ | ìƒˆ íŒŒí‹°ì…˜ ì´ˆê¸°í™”     |

> ğŸ§  **í•µì‹¬ í¬ì¸íŠ¸:**
> ë¦¬ë°¸ëŸ°ìŠ¤ ì¤‘ì—ëŠ” **ì¤‘ë³µ ì²˜ë¦¬** ë˜ëŠ” **ëˆ„ë½**ì´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
> ì´ ë¦¬ìŠ¤ë„ˆë¥¼ í†µí•´ ë°˜ë“œì‹œ ì˜¤í”„ì…‹ì„ í™•ì‹¤íˆ ì»¤ë°‹í•´ì•¼ í•¨.

### âœï¸ ë‚´ ìƒê°

> ì»¨ìŠˆë¨¸ ì¥ì•  ë³µêµ¬ ì‹œ ì˜¤í”„ì…‹ ë¶ˆì¼ì¹˜ë¡œ ì¸í•´ ì¤‘ë³µ ì²˜ë¦¬ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°ê°€ ë§ì€ë°,
> ì´ ë¦¬ìŠ¤ë„ˆë¥¼ í™œìš©í•˜ë©´ â€œì •í™•íˆ í•œ ë²ˆ(exactly once)â€ì— ê°€ê¹Œìš´ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.

---

## 4.8 íŠ¹ì • ì˜¤í”„ì…‹ì˜ ë ˆì½”ë“œ ì½ê¸° (Seeking to Offsets)

### ğŸ“í•µì‹¬ ê¸°ëŠ¥

* ê¸°ë³¸ì ìœ¼ë¡œ ì»¨ìŠˆë¨¸ëŠ” **ë§ˆì§€ë§‰ ì»¤ë°‹ëœ ì˜¤í”„ì…‹ë¶€í„°** ì½ì§€ë§Œ,
  íŠ¹ì • ìœ„ì¹˜(ì‹œê°„, ì˜¤í”„ì…‹, ì²˜ìŒ/ë)ë¡œ ì´ë™ ê°€ëŠ¥.

| ë©”ì„œë“œ                       | ì„¤ëª…                      |
| ------------------------- | ----------------------- |
| `seekToBeginning()`       | íŒŒí‹°ì…˜ì˜ ì²˜ìŒë¶€í„° ì½ê¸°            |
| `seekToEnd()`             | ìµœì‹  ë©”ì‹œì§€ë¶€í„° ì½ê¸°             |
| `seek(partition, offset)` | ì§€ì •í•œ ì˜¤í”„ì…‹ë¶€í„° ì½ê¸° ì‹œì‘         |
| `offsetsForTimes(map)`    | íŠ¹ì • íƒ€ì„ìŠ¤íƒ¬í”„ì— í•´ë‹¹í•˜ëŠ” ì˜¤í”„ì…‹ìœ¼ë¡œ ì´ë™ |

ì˜ˆì œ:

```kotlin
val oneHourAgo = Instant.now().minusSeconds(3600).toEpochMilli()
val timestampsToSearch = consumer.assignment().associateWith { oneHourAgo }
val offsets = consumer.offsetsForTimes(timestampsToSearch)

offsets.forEach { (tp, offsetAndTimestamp) ->
    if (offsetAndTimestamp != null) consumer.seek(tp, offsetAndTimestamp.offset())
}
```

> ğŸ§  **í™œìš© ì˜ˆì‹œ:**
>
> * ë¡œê·¸ ë¶„ì„ ì‹œ íŠ¹ì • ì‹œì  ì´í›„ ë°ì´í„°ë§Œ ì¬ì²˜ë¦¬
> * ë°ì´í„° ìœ ì‹¤ ë³µêµ¬ ì‹œ íŠ¹ì • ì˜¤í”„ì…‹ìœ¼ë¡œ ì¬ì‹œì‘

### âœï¸ ë‚´ ìƒê°

> `seek()`ì€ ë‹¨ìˆœí•˜ë©´ì„œë„ ê°•ë ¥í•œ APIì…ë‹ˆë‹¤.
> ìš´ì˜ ì¤‘ ì¥ì•  ë³µêµ¬ë‚˜ â€œíƒ€ì„ë¼ì¸ ê¸°ì¤€ ë³µì›â€ ì‹œ ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.

---

## ğŸ§µ 4.9 í´ë§ ë£¨í”„ ì¢…ë£Œ ì²˜ë¦¬ (Graceful Shutdown)

### ğŸ“í•µì‹¬ ê°œë…

* `poll()`ì€ ë¸”ë¡œí‚¹ í˜¸ì¶œì´ë¯€ë¡œ, **ë‹¤ë¥¸ ìŠ¤ë ˆë“œì—ì„œ ì•ˆì „í•˜ê²Œ ì¢…ë£Œ ì‹ í˜¸ë¥¼ ë³´ë‚´ì•¼ í•¨**
* ìœ ì¼í•˜ê²Œ â€œìŠ¤ë ˆë“œ ì•ˆì „í•œ ë©”ì„œë“œâ€ëŠ” `consumer.wakeup()`

```kotlin
val mainThread = Thread.currentThread()

Runtime.getRuntime().addShutdownHook(Thread {
    println("Shutdown detected.")
    consumer.wakeup()
    mainThread.join()
})

try {
    while (true) {
        val records = consumer.poll(Duration.ofMillis(100))
        // ... message processing
    }
} catch (e: WakeupException) {
    println("Consumer is shutting down.")
} finally {
    consumer.close()
}
```

| ë©”ì„œë“œ                 | ì„¤ëª…                                |
| ------------------- | --------------------------------- |
| `consumer.wakeup()` | í´ë§ì„ ì¦‰ì‹œ ì¤‘ë‹¨ì‹œí‚¤ê³  `WakeupException` ë°œìƒ |
| `consumer.close()`  | ì˜¤í”„ì…‹ ì»¤ë°‹ + ê·¸ë£¹ íƒˆí‡´ ìˆ˜í–‰                 |

> ğŸ’¡ `wakeup()`ì€ ì»¨ìŠˆë¨¸ API ì¤‘ **ìœ ì¼í•˜ê²Œ thread-safe**í•œ ë©”ì„œë“œì…ë‹ˆë‹¤.

### âœï¸ ë‚´ ìƒê°

> â€œCtrl+C ì‹œ ì•ˆì „ì¢…ë£Œâ€ëŠ” ìš´ì˜í™˜ê²½ì—ì„œ ë°˜ë“œì‹œ êµ¬í˜„í•´ì•¼ í•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤.
> íŠ¹íˆ ë¹„ë™ê¸° ì»¤ë°‹ ì‚¬ìš© ì‹œ, ì¢…ë£Œ ì „ì— `commitSync()`ë¡œ ë³´ì •í•˜ëŠ” ìŠµê´€ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

---

## 4.10 ë””ì‹œë¦¬ì–¼ë¼ì´ì € (Deserializer)

### ğŸ“í•µì‹¬ ê°œë…

* í”„ë¡œë“€ì„œê°€ ë³´ë‚¸ ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ ì—­ì§ë ¬í™”í•˜ì—¬ ì»¨ìŠˆë¨¸ ì¸¡ ê°ì²´ë¡œ ë³µì›
* Kafkaì˜ `Deserializer<T>` ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„

```java
public class CustomerDeserializer implements Deserializer<Customer> {
    @Override
    public Customer deserialize(String topic, byte[] data) {
        if (data == null || data.length < 8)
            throw new SerializationException("Invalid data");

        ByteBuffer buffer = ByteBuffer.wrap(data);
        int id = buffer.getInt();
        int nameSize = buffer.getInt();
        byte[] nameBytes = new byte[nameSize];
        buffer.get(nameBytes);

        return new Customer(id, new String(nameBytes, "UTF-8"));
    }
}
```

**ì‚¬ìš© ì‹œ:**

```java
props.put("value.deserializer", CustomerDeserializer.class.getName());
KafkaConsumer<String, Customer> consumer = new KafkaConsumer<>(props);
```

| êµ¬ì„± ìš”ì†Œ             | ì„¤ëª…           |
| ----------------- | ------------ |
| `Deserializer<T>` | ì—­ì§ë ¬í™” ì¸í„°í˜ì´ìŠ¤   |
| `deserialize()`   | ë°”ì´íŠ¸ â†’ ê°ì²´ ë³€í™˜  |
| `close()`         | ìì› í•´ì œ (í•„ìš” ì‹œ) |

> **í•µì‹¬ ì›ì¹™:**
> í”„ë¡œë“€ì„œì˜ ì‹œë¦¬ì–¼ë¼ì´ì €ì™€ ì»¨ìŠˆë¨¸ì˜ ë””ì‹œë¦¬ì–¼ë¼ì´ì €ëŠ” í•­ìƒ ë™ì¼í•œ ë¡œì§/íƒ€ì…ì´ì–´ì•¼ í•¨.

### âœï¸ ë‚´ ìƒê°

> ì»¤ìŠ¤í…€ ì§ë ¬í™”ëŠ” íƒ€ì… ì•ˆì •ì„±ê³¼ ë²„ì „ ê´€ë¦¬ ë¦¬ìŠ¤í¬ê°€ í¬ê¸° ë•Œë¬¸ì—
> ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” **Avro / JSON / Protobuf + Schema Registry** ë°©ì‹ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ê²Œ ì´ìƒì ì…ë‹ˆë‹¤.



---

## ğŸ§  ì „ì²´ ìš”ì•½

| êµ¬ë¶„ | í•µì‹¬ í‚¤ì›Œë“œ                 | ìš”ì•½                |
| -- | ---------------------- | ----------------- |
| ê°œë… | ì»¨ìŠˆë¨¸, ê·¸ë£¹, ë¦¬ë°¸ëŸ°ìŠ¤          | ë³‘ë ¬ì²˜ë¦¬ì™€ í™•ì¥ì„±ì˜ í•µì‹¬ êµ¬ì¡°  |
| ìƒì„± | KafkaConsumer          | ë¸Œë¡œì»¤ ì—°ê²° ë° ì§ë ¬í™” ì„¤ì •   |
| êµ¬ë… | subscribe              | ì •ê·œì‹ êµ¬ë… ë° ìë™ ë¦¬ë°¸ëŸ°ìŠ¤  |
| í´ë§ | poll loop              | ì£¼ê¸°ì  í˜¸ì¶œë¡œ ì»¨ìŠˆë¨¸ ìƒì¡´ ìœ ì§€ |
| ì„¤ì • | fetch / poll / timeout | ì§€ì—°, ì²˜ë¦¬ëŸ‰, ì•ˆì •ì„± ë°¸ëŸ°ìŠ¤  |
| ì»¤ë°‹ | offset commit          | ì²˜ë¦¬ ì™„ë£Œ ìƒíƒœ ê´€ë¦¬ì˜ í•µì‹¬   |

---

## ğŸ’» Kotlin ì˜ˆì œ â€” as-is / to-be

### ğŸ§© As-Is (ë‹¨ìˆœ ìë™ ì»¤ë°‹ ê¸°ë°˜)

```kotlin
val props = Properties().apply {
    put("bootstrap.servers", "localhost:9092")
    put("group.id", "order-consumer")
    put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer")
    put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer")
    put("enable.auto.commit", "true")
}

val consumer = KafkaConsumer<String, String>(props)
consumer.subscribe(listOf("order-events"))

while (true) {
    val records = consumer.poll(Duration.ofMillis(100))
    for (record in records) {
        println("Order received: ${record.value()}")
    }
}
```

---

### ğŸš€ To-Be (ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸ + ìˆ˜ë™ ì»¤ë°‹ + ì•ˆì „ ì²˜ë¦¬)

```kotlin
data class OrderEvent(val orderId: String, val amount: Double)

class OrderProcessor {
    fun process(event: OrderEvent): Boolean {
        // âœ… ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ì²˜ë¦¬: DB ì—…ë°ì´íŠ¸ or ê²°ì œ ë¡œì§
        println("Processing order ${event.orderId} - ${event.amount}")
        return true
    }
}

fun main() {
    val props = Properties().apply {
        put("bootstrap.servers", "localhost:9092")
        put("group.id", "order-processor-group")
        put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer")
        put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer")
        put("enable.auto.commit", "false")
    }

    val consumer = KafkaConsumer<String, String>(props)
    val processor = OrderProcessor()

    consumer.subscribe(listOf("order-events"))

    while (true) {
        val records = consumer.poll(Duration.ofMillis(100))
        try {
            for (record in records) {
                val event = OrderEvent(record.key(), record.value().toDouble())
                if (processor.process(event)) {
                    // âœ… ì²˜ë¦¬ ì„±ê³µ ì‹œë§Œ ì»¤ë°‹
                    consumer.commitSync(mapOf(TopicPartition(record.topic(), record.partition()) 
                        to OffsetAndMetadata(record.offset() + 1)))
                }
            }
        } catch (ex: Exception) {
            println("Error: ${ex.message}, skip and continue")
        }
    }
}
```

---

### ğŸ§ª Kotest í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ

```kotlin
class OrderProcessorTest : StringSpec({
    "should process valid order events" {
        val processor = OrderProcessor()
        val event = OrderEvent("ORD-001", 15000.0)
        processor.process(event) shouldBe true
    }
})
```

---

## ğŸ“š ì°¸ê³  ë§í¬

* [Apache Kafka Consumer Configs (ê³µì‹ ë¬¸ì„œ)](https://kafka.apache.org/documentation/#consumerconfigs)
* [Confluent Blog - Cooperative Rebalancing Explained](https://www.confluent.io/blog/cooperative-rebalancing-in-kafka/)
* [Jesse Anderson - Kafkaâ€™s Got a Brand-New Poll](https://www.jesse-anderson.com/2020/09/kafkas-got-a-brand-new-poll/)
* [Kafka ConsumerRebalanceListener Docs](https://kafka.apache.org/documentation/#consumerapi)
* [Confluent Blog - Rebalance Patterns](https://www.confluent.io/blog/cooperative-rebalancing-in-kafka/)
* [Apache Avro & Schema Registry Integration Guide](https://docs.confluent.io/platform/current/schema-registry/)
