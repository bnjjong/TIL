# 🧩 제4장 전체 개요 — “카프카 컨슈머: 카프카에서 데이터 읽기”

이 장은 **KafkaConsumer API의 개념과 동작 원리, 설정, 오프셋 커밋 전략**을 다루며,
프로듀서(쓰기)에 대응되는 **컨슈머(읽기)** 측의 모든 핵심 메커니즘을 설명합니다.

---

## 4.1 컨슈머 개념

### 📍핵심 개념 요약

| 구분                         | 내용                                  |
| -------------------------- | ----------------------------------- |
| **컨슈머(Consumer)**          | 토픽에서 데이터를 읽어오는 Kafka 클라이언트          |
| **컨슈머 그룹(Consumer Group)** | 여러 컨슈머가 협력하여 토픽 파티션을 분산 처리하는 단위     |
| **파티션 할당**                 | 그룹 내 각 컨슈머가 서로 다른 파티션을 맡음           |
| **리밸런스(Rebalance)**        | 그룹 내 컨슈머 수나 토픽 파티션 구조가 변할 때 재할당     |
| **정적 멤버십**                 | 컨슈머 재시작 시 기존 파티션을 유지하여 불필요한 리밸런스 방지 |

### ✏️ 내 생각

> Kafka 컨슈머의 **확장성의 핵심 구조**를 설명합니다.
> 실제 운영에서는 **정적 그룹 멤버십** 설정을 활용해 리밸런스 비용을 줄이는 것이 중요.

---

## 4.2 컨슈머 생성하기

`KafkaConsumer` 인스턴스를 생성할 때 필수 속성은 다음과 같습니다.

| 속성                                        | 설명           |
| ----------------------------------------- | ------------ |
| `bootstrap.servers`                       | 브로커 접속 정보    |
| `key.deserializer` / `value.deserializer` | 메시지 역직렬화 클래스 |
| `group.id`                                | 컨슈머 그룹 식별자   |

---

## 4.3 토픽 구독하기

컨슈머는 `subscribe()`를 통해 토픽을 구독합니다.

* 특정 토픽 이름 또는 정규식(`Pattern.compile("test.*")`)으로 구독 가능
* 정규식 사용 시, 새로 추가되는 토픽도 자동 포함
* 단, 토픽/파티션 수가 많을 때는 클러스터 부하 증가에 주의

---

## 4.4 폴링 루프 (poll loop)

카프카 컨슈머는 **“계속 폴링하지 않으면 죽은 것으로 간주된다.”**

```java
while (true) {
  val records = consumer.poll(Duration.ofMillis(100))
  for (record in records) {
    println("topic=${record.topic()}, offset=${record.offset()}")
  }
}
```

* `poll()`은 데이터를 요청하고 일정 시간 기다림
* `max.poll.interval.ms` 이상 호출되지 않으면 컨슈머는 “죽은” 것으로 판단되어 리밸런스 발생
* 하나의 컨슈머 인스턴스는 하나의 스레드에서만 안전하게 사용 가능

### ✏️ 내 생각

> “폴링 루프”는 카프카 컨슈머의 생명선입니다.
> CPU 바운드/IO 바운드 작업은 별도 워커 스레드로 분리해야 합니다.

---

## 4.5 컨슈머 설정 (Configuration)

### ⚙️ 주요 성능/신뢰성 관련 옵션 요약

| 속성                              | 설명                                                                |
| ------------------------------- | ----------------------------------------------------------------- |
| `fetch.min.bytes`               | 최소 데이터 양, 너무 작으면 요청 과다 발생                                         |
| `fetch.max.wait.ms`             | 최대 대기 시간, fetch.min.bytes와 함께 조정                                  |
| `fetch.max.bytes`               | 한 번에 받을 최대 데이터 크기                                                 |
| `session.timeout.ms`            | 하트비트 미수신 시 그룹 탈퇴까지의 시간                                            |
| `heartbeat.interval.ms`         | 하트비트 전송 주기                                                        |
| `max.poll.records`              | 한 번의 poll에서 처리할 최대 레코드 수                                          |
| `auto.offset.reset`             | 유효 오프셋이 없을 때 시작 위치(`latest`/`earliest`)                           |
| `enable.auto.commit`            | 자동 커밋 여부                                                          |
| `partition.assignment.strategy` | 파티션 분배 알고리즘(`Range`, `RoundRobin`, `Sticky`, `CooperativeSticky`) |

### ✏️ 내 생각

> **Sticky + CooperativeSticky** 조합은 최신 Kafka(3.1+)에서 사실상 표준입니다.
> 안정성과 효율성이 모두 개선됩니다.

---

## 4.6 오프셋과 커밋 (Offset & Commit)

| 커밋 유형                               | 특징                 |
| ----------------------------------- | ------------------ |
| **자동 커밋 (enable.auto.commit=true)** | 간단하지만 중복 처리 가능성 높음 |
| **수동 커밋 (commitSync)**              | 안전하지만 블로킹          |
| **비동기 커밋 (commitAsync)**            | 빠르지만 실패 시 재시도 필요   |

**핵심 개념**

* Kafka는 “마지막으로 성공 처리된 오프셋”을 커밋하여 **idempotent 처리 보장**
* `_consumer_offsets` 토픽에 저장됨
* 커밋 위치 오류 시 중복 처리(Too low offset) 또는 유실(Too high offset) 발생 가능

## 4.7 리밸런스 리스너 (ConsumerRebalanceListener)

### 📍핵심 개념

* 컨슈머 그룹 내 파티션이 재할당될 때 **오프셋을 안전하게 커밋**하기 위해 사용
* `ConsumerRebalanceListener`를 구현하면
  리밸런스 시점(before/after)에 커밋/초기화 작업 수행 가능

```java
consumer.subscribe(List.of("orders"), new ConsumerRebalanceListener() {
    @Override
    public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
        // 리밸런스 직전, 현재 처리 완료된 오프셋을 커밋
        consumer.commitSync(currentOffsets)
    }

    @Override
    public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
        // 새 파티션 할당 시 필요한 초기화 로직
    }
});
```

| 메서드                    | 호출 시점  | 주요 역할         |
| ---------------------- | ------ | ------------- |
| `onPartitionsRevoked`  | 리밸런스 전 | 기존 파티션 오프셋 커밋 |
| `onPartitionsAssigned` | 리밸런스 후 | 새 파티션 초기화     |

> 🧠 **핵심 포인트:**
> 리밸런스 중에는 **중복 처리** 또는 **누락**이 발생할 수 있으므로
> 이 리스너를 통해 반드시 오프셋을 확실히 커밋해야 함.

### ✏️ 내 생각

> 컨슈머 장애 복구 시 오프셋 불일치로 인해 중복 처리가 발생하는 경우가 많은데,
> 이 리스너를 활용하면 “정확히 한 번(exactly once)”에 가까운 처리가 가능해집니다.

---

## 4.8 특정 오프셋의 레코드 읽기 (Seeking to Offsets)

### 📍핵심 기능

* 기본적으로 컨슈머는 **마지막 커밋된 오프셋부터** 읽지만,
  특정 위치(시간, 오프셋, 처음/끝)로 이동 가능.

| 메서드                       | 설명                      |
| ------------------------- | ----------------------- |
| `seekToBeginning()`       | 파티션의 처음부터 읽기            |
| `seekToEnd()`             | 최신 메시지부터 읽기             |
| `seek(partition, offset)` | 지정한 오프셋부터 읽기 시작         |
| `offsetsForTimes(map)`    | 특정 타임스탬프에 해당하는 오프셋으로 이동 |

예제:

```kotlin
val oneHourAgo = Instant.now().minusSeconds(3600).toEpochMilli()
val timestampsToSearch = consumer.assignment().associateWith { oneHourAgo }
val offsets = consumer.offsetsForTimes(timestampsToSearch)

offsets.forEach { (tp, offsetAndTimestamp) ->
    if (offsetAndTimestamp != null) consumer.seek(tp, offsetAndTimestamp.offset())
}
```

> 🧠 **활용 예시:**
>
> * 로그 분석 시 특정 시점 이후 데이터만 재처리
> * 데이터 유실 복구 시 특정 오프셋으로 재시작

### ✏️ 내 생각

> `seek()`은 단순하면서도 강력한 API입니다.
> 운영 중 장애 복구나 “타임라인 기준 복원” 시 매우 유용합니다.

---

## 🧵 4.9 폴링 루프 종료 처리 (Graceful Shutdown)

### 📍핵심 개념

* `poll()`은 블로킹 호출이므로, **다른 스레드에서 안전하게 종료 신호를 보내야 함**
* 유일하게 “스레드 안전한 메서드”는 `consumer.wakeup()`

```kotlin
val mainThread = Thread.currentThread()

Runtime.getRuntime().addShutdownHook(Thread {
    println("Shutdown detected.")
    consumer.wakeup()
    mainThread.join()
})

try {
    while (true) {
        val records = consumer.poll(Duration.ofMillis(100))
        // ... message processing
    }
} catch (e: WakeupException) {
    println("Consumer is shutting down.")
} finally {
    consumer.close()
}
```

| 메서드                 | 설명                                |
| ------------------- | --------------------------------- |
| `consumer.wakeup()` | 폴링을 즉시 중단시키고 `WakeupException` 발생 |
| `consumer.close()`  | 오프셋 커밋 + 그룹 탈퇴 수행                 |

> 💡 `wakeup()`은 컨슈머 API 중 **유일하게 thread-safe**한 메서드입니다.

### ✏️ 내 생각

> “Ctrl+C 시 안전종료”는 운영환경에서 반드시 구현해야 하는 패턴입니다.
> 특히 비동기 커밋 사용 시, 종료 전에 `commitSync()`로 보정하는 습관이 중요합니다.

---

## 4.10 디시리얼라이저 (Deserializer)

### 📍핵심 개념

* 프로듀서가 보낸 바이트 데이터를 역직렬화하여 컨슈머 측 객체로 복원
* Kafka의 `Deserializer<T>` 인터페이스 구현

```java
public class CustomerDeserializer implements Deserializer<Customer> {
    @Override
    public Customer deserialize(String topic, byte[] data) {
        if (data == null || data.length < 8)
            throw new SerializationException("Invalid data");

        ByteBuffer buffer = ByteBuffer.wrap(data);
        int id = buffer.getInt();
        int nameSize = buffer.getInt();
        byte[] nameBytes = new byte[nameSize];
        buffer.get(nameBytes);

        return new Customer(id, new String(nameBytes, "UTF-8"));
    }
}
```

**사용 시:**

```java
props.put("value.deserializer", CustomerDeserializer.class.getName());
KafkaConsumer<String, Customer> consumer = new KafkaConsumer<>(props);
```

| 구성 요소             | 설명           |
| ----------------- | ------------ |
| `Deserializer<T>` | 역직렬화 인터페이스   |
| `deserialize()`   | 바이트 → 객체 변환  |
| `close()`         | 자원 해제 (필요 시) |

> **핵심 원칙:**
> 프로듀서의 시리얼라이저와 컨슈머의 디시리얼라이저는 항상 동일한 로직/타입이어야 함.

### ✏️ 내 생각

> 커스텀 직렬화는 타입 안정성과 버전 관리 리스크가 크기 때문에
> 실제 운영에서는 **Avro / JSON / Protobuf + Schema Registry** 방식으로 관리하는 게 이상적입니다.



---

## 🧠 전체 요약

| 구분 | 핵심 키워드                 | 요약                |
| -- | ---------------------- | ----------------- |
| 개념 | 컨슈머, 그룹, 리밸런스          | 병렬처리와 확장성의 핵심 구조  |
| 생성 | KafkaConsumer          | 브로커 연결 및 직렬화 설정   |
| 구독 | subscribe              | 정규식 구독 및 자동 리밸런스  |
| 폴링 | poll loop              | 주기적 호출로 컨슈머 생존 유지 |
| 설정 | fetch / poll / timeout | 지연, 처리량, 안정성 밸런스  |
| 커밋 | offset commit          | 처리 완료 상태 관리의 핵심   |

---

## 💻 Kotlin 예제 — as-is / to-be

### 🧩 As-Is (단순 자동 커밋 기반)

```kotlin
val props = Properties().apply {
    put("bootstrap.servers", "localhost:9092")
    put("group.id", "order-consumer")
    put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer")
    put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer")
    put("enable.auto.commit", "true")
}

val consumer = KafkaConsumer<String, String>(props)
consumer.subscribe(listOf("order-events"))

while (true) {
    val records = consumer.poll(Duration.ofMillis(100))
    for (record in records) {
        println("Order received: ${record.value()}")
    }
}
```

---

### 🚀 To-Be (비즈니스 도메인 + 수동 커밋 + 안전 처리)

```kotlin
data class OrderEvent(val orderId: String, val amount: Double)

class OrderProcessor {
    fun process(event: OrderEvent): Boolean {
        // ✅ 실제 비즈니스 처리: DB 업데이트 or 결제 로직
        println("Processing order ${event.orderId} - ${event.amount}")
        return true
    }
}

fun main() {
    val props = Properties().apply {
        put("bootstrap.servers", "localhost:9092")
        put("group.id", "order-processor-group")
        put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer")
        put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer")
        put("enable.auto.commit", "false")
    }

    val consumer = KafkaConsumer<String, String>(props)
    val processor = OrderProcessor()

    consumer.subscribe(listOf("order-events"))

    while (true) {
        val records = consumer.poll(Duration.ofMillis(100))
        try {
            for (record in records) {
                val event = OrderEvent(record.key(), record.value().toDouble())
                if (processor.process(event)) {
                    // ✅ 처리 성공 시만 커밋
                    consumer.commitSync(mapOf(TopicPartition(record.topic(), record.partition()) 
                        to OffsetAndMetadata(record.offset() + 1)))
                }
            }
        } catch (ex: Exception) {
            println("Error: ${ex.message}, skip and continue")
        }
    }
}
```

---

### 🧪 Kotest 테스트 예시

```kotlin
class OrderProcessorTest : StringSpec({
    "should process valid order events" {
        val processor = OrderProcessor()
        val event = OrderEvent("ORD-001", 15000.0)
        processor.process(event) shouldBe true
    }
})
```

---

## 📚 참고 링크

* [Apache Kafka Consumer Configs (공식 문서)](https://kafka.apache.org/documentation/#consumerconfigs)
* [Confluent Blog - Cooperative Rebalancing Explained](https://www.confluent.io/blog/cooperative-rebalancing-in-kafka/)
* [Jesse Anderson - Kafka’s Got a Brand-New Poll](https://www.jesse-anderson.com/2020/09/kafkas-got-a-brand-new-poll/)
* [Kafka ConsumerRebalanceListener Docs](https://kafka.apache.org/documentation/#consumerapi)
* [Confluent Blog - Rebalance Patterns](https://www.confluent.io/blog/cooperative-rebalancing-in-kafka/)
* [Apache Avro & Schema Registry Integration Guide](https://docs.confluent.io/platform/current/schema-registry/)
