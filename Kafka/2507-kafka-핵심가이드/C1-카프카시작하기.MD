# CHAPTER 1: 카프카 시작하기 — 자세한 정리

## 1.1 발행/구독 메시지 전달

### 1.1.1 발행/구독(Pub/Sub) 패턴의 개념
- **발행자(Producer)** 와 **구독자(Consumer)** 가 직접 연결되지 않고, 중간 **브로커(Broker)** 를 통해 메시지를 주고받는 구조.
- 발행자는 메시지를 **토픽(Topic)** 에 발행하고, 구독자는 관심 있는 토픽을 구독하여 메시지를 받음.
- 이 구조는 시스템 간 결합도를 낮추고, 유연성과 확장성을 높임[1][2][3].

### 1.1.2 기존 방식과의 비교
- 초기에는 단순히 한 서비스가 다른 서비스로 직접 메시지를 전달.
- 서비스가 늘어나면 연결이 복잡해지고, 유지보수가 어려워짐.
- 브로커를 도입하면 모든 메시지를 중앙에서 관리하고, 필요한 서비스만 구독하도록 단순화됨.

### 1.1.3 메시지 큐와 Pub/Sub 시스템의 차이
- **메시지 큐**: 한 메시지를 한 소비자만 받음(PTP, Point-to-Point).
- **Pub/Sub**: 여러 소비자가 같은 메시지를 독립적으로 받을 수 있음.
- `카프카는 Pub/Sub 패턴을 기본`으로 하며, 큐잉 모델도 지원함.

## 1.2 카프카 입문

### 1.2.1 카프카란?
- **아파치 카프카(Apache Kafka)** 는 대용량 데이터를 빠르고 안정적으로 처리하는 **분산 메시징 플랫폼**.
- **토픽**: 메시지를 분류하는 논리적 단위.
- **파티션**: 토픽을 여러 조각으로 나눠 저장, 확장성과 장애 대응에 유리.
- **프로듀서**: 메시지 생성 및 발행.
- **컨슈머**: 메시지 구독 및 소비.
- **브로커**: 메시지 저장과 전달을 담당하는 서버.
- **클러스터**: 여러 브로커의 집합으로, 대규모 처리를 지원.

### 1.2.2 메시지와 배치
- 메시지는 **배치(batch)** 단위로 저장되어 네트워크 효율 및 처리량을 높임.
    - `여러 개의 메시지를 하나로 묶어서 한 번에 저장하고 전송`하는 방식
    - 일정량이 쌓이거나 일정 시간이 지나면 `한 번에 묶어서 브로커로 보냄`
- 배치 크기를 조절해 처리량과 지연시간을 트레이드오프 할 수 있음.

### 1.2.3 스키마
- 메시지 구조를 명확히 정의(예: Avro, JSON 등).
    - 대용량 처리에는 Avro가 좋음.(바이너리 처리)
        - 스키마가 변경되어도 하위,상위 호환이 가능.
- 스키마를 통해 데이터의 일관성과 호환성을 유지.

### 1.2.4 토픽과 파티션
- 토픽은 여러 파티션으로 나뉘어 저장됨.
- 파티션은 순서가 보장되며, 복제되어 장애에 강함.
- 파티션별로 메시지의 **오프셋(offset)** 이 관리됨.

### 1.2.5 프로듀서와 컨슈머
- 프로듀서는 메시지를 토픽에 발행(파티션 지정 가능).
- 컨슈머는 토픽을 구독해 메시지를 읽음.
- **컨슈머 그룹**: 여러 컨슈머가 협력해 파티션을 나눠 읽음(수평 확장 가능).

### 1.2.6 브로커와 클러스터
- 브로커는 메시지 저장/전달을 담당.
- 클러스터 내 여러 브로커가 파티션을 나눠 담당(리더/팔로워 구조).
- 파티션 복제를 통해 장애 발생 시 데이터 손실 방지.

### 1.2.7 다중 클러스터
- 데이터 유형별 분리, 보안, 재해 복구 등 목적에 따라 여러 클러스터 운용 가능.
- 미러메이커(MirrorMaker) 등 도구로 클러스터 간 데이터 복제 지원.

## 1.3 왜 카프카인가?

- **여러 프로듀서/컨슈머 지원**: 다양한 시스템이 동시에 메시지 생산/소비 가능.
- **디스크 기반 보존**: 메시지를 일정 기간 저장, 실시간이 아니어도 데이터 유실 없음.
- **확장성**: 브로커 추가로 손쉽게 확장.
- **고성능**: 대량의 메시지를 빠르게 처리.
- **플랫폼 기능**: 커넥트, 스트림즈 등 다양한 확장 기능 제공[4][5][6].

## 1.4 데이터 생태계

- **데이터 파이프라인의 중심**: 다양한 시스템과 연계하여 데이터의 생산, 변환, 소비를 담당.
- **활용 사례**
  - 사용자 활동 추적
  - 메시지 교환(알림 등)
  - 지표/로그 수집
  - 커밋 로그
  - 실시간 스트림 처리

## 1.5 카프카의 기원

- **링크드인에서 시작**: 대규모 데이터 파이프라인 문제 해결을 위해 개발.
- **오픈소스화 및 생태계 확장**: 다양한 기업과 커뮤니티에서 사용, 발전 중.
- **컨플루언트(Confluent)** 등 상업적 지원 및 서비스 제공.

## 요약

**카프카는 대용량 실시간 데이터 처리와 시스템 간 데이터 연동을 위해 설계된 분산 메시징 플랫폼이다. 발행/구독 구조, 높은 확장성, 내결함성, 다양한 활용 사례를 통해 현대 데이터 생태계의 핵심 역할을 수행한다.**

# 예제 코드 (Kotlin) — as-is / to-be, 도메인 로직 기반

## 도메인 예시: 주문(Order) 이벤트 처리

### as-is: 직접 연결 방식 (비권장)

```kotlin
// 주문이 생성될 때마다 직접 이메일 서비스 호출
class OrderService(private val emailService: EmailService) {
    fun createOrder(order: Order) {
        // 주문 생성 로직
        emailService.sendOrderConfirmation(order)
    }
}

class EmailService {
    fun sendOrderConfirmation(order: Order) {
        println("이메일 발송: 주문번호=${order.id}")
    }
}
```

### to-be: 카프카 Pub/Sub 구조 적용

```kotlin
import org.apache.kafka.clients.producer.KafkaProducer
import org.apache.kafka.clients.producer.ProducerRecord
import org.apache.kafka.clients.consumer.KafkaConsumer
import org.json.JSONObject
import java.time.Duration

// 주문 생성 시 카프카에 이벤트 발행
class OrderService(private val kafkaProducer: KafkaProducer<String, String>) {
    fun createOrder(order: Order) {
        // 주문 생성 로직
        val event = """{"orderId":"${order.id}","status":"CREATED"}"""
        kafkaProducer.send(ProducerRecord("order-events", order.id, event))
    }
}

// 이메일 서비스는 카프카에서 이벤트를 구독
class EmailService(private val kafkaConsumer: KafkaConsumer<String, String>) {
    fun listenOrderEvents() {
        kafkaConsumer.subscribe(listOf("order-events"))
        while (true) {
            val records = kafkaConsumer.poll(Duration.ofMillis(100))
            for (record in records) {
                val orderId = JSONObject(record.value())["orderId"]
                println("이메일 발송: 주문번호=$orderId")
            }
        }
    }
}
```

## Kotest 테스트 코드 예시 (Embedded Kafka 활용)

```kotlin
import io.kotest.core.spec.style.FunSpec
import io.kotest.extensions.embedded.kafka.embeddedKafkaListener
import io.kotest.matchers.shouldBe
import org.apache.kafka.clients.producer.ProducerRecord
import java.time.Duration

class OrderKafkaIntegrationTest : FunSpec({
    listener(embeddedKafkaListener)

    test("주문 이벤트가 이메일 서비스에 전달된다") {
        val producer = embeddedKafkaListener.stringStringProducer()
        val event = """{"orderId":"1234","status":"CREATED"}"""
        producer.send(ProducerRecord("order-events", "1234", event))
        producer.close()

        val consumer = embeddedKafkaListener.stringStringConsumer("order-events")
        val record = consumer.poll(Duration.ofSeconds(1)).first()
        record.value() shouldBe event
        consumer.close()
    }
})
```

## 추가 예제: 주문 상태 변경 이벤트

### as-is: 서비스 간 직접 호출

```kotlin
class OrderStatusService(private val notificationService: NotificationService) {
    fun updateStatus(orderId: String, status: String) {
        // 상태 변경 로직
        notificationService.notifyOrderStatus(orderId, status)
    }
}
```

### to-be: 카프카 이벤트 기반

```kotlin
class OrderStatusService(private val kafkaProducer: KafkaProducer<String, String>) {
    fun updateStatus(orderId: String, status: String) {
        val event = """{"orderId":"$orderId","status":"$status"}"""
        kafkaProducer.send(ProducerRecord("order-status-events", orderId, event))
    }
}

class NotificationService(private val kafkaConsumer: KafkaConsumer<String, String>) {
    fun listenOrderStatusEvents() {
        kafkaConsumer.subscribe(listOf("order-status-events"))
        while (true) {
            val records = kafkaConsumer.poll(Duration.ofMillis(100))
            for (record in records) {
                val status = JSONObject(record.value())["status"]
                println("알림: 주문 상태 변경 - $status")
            }
        }
    }
}
```

## 참고

- 실제 카프카 연동을 위해서는 `kafka-clients` 의존성, 클러스터 주소, 직렬화/역직렬화 설정 등이 필요합니다.
- Embedded Kafka 및 Kotest 확장 활용 시, 테스트 환경에서 실제 브로커 없이 통합 테스트가 가능합니다[7][8][9].

**이 구조를 통해 도메인 이벤트 기반의 확장성과 유연성을 확보할 수 있습니다.**

출처
[1] Kafka's Pivotal Role In Enabling Pub-sub Architectures | Ashnik https://www.ashnik.com/kafkas-pivotal-role-in-enabling-pub-sub-architectures/
[2] Related Content you might be interested in https://subscription.packtpub.com/book/data/9781787283985/1/ch01lvl1sec05/publish-subscribe-messaging-system
[3] Publish-Subscribe Model in Kafka https://dzone.com/articles/publish-subscribe-model-in-kafka
[4] Kafka Summary PDF | Neha Narkhede https://www.bookey.app/book/kafka-by-neha-narkhede
[5] Apache Kafka — Overview - Data Engineer Things https://blog.det.life/apache-kafka-overview-b04c4ab8ef49
[6] Kafka 4.0 Documentation https://kafka.apache.org/documentation/
[7] Kafka producer and consumer written with Kotlin - Lanky Dan Blog https://lankydan.dev/kafka-producer-and-consumer-written-with-kotlin
[8] Embedded Kafka Extension - Kotest https://kotest.io/docs/extensions/embedded-kafka.html
[9] Kotest에서 TestContainers 적용하기 대모험 - velog https://velog.io/@glencode/Kotest%EC%97%90%EC%84%9C-TestContainers-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0-%EB%8C%80%EB%AA%A8%ED%97%98
[10] kapeuka-haegsimgaideu-2nd_230501-pages-29-46.pdf https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/32004849/f3f498b7-4c0f-47f2-ae35-1fc235ded36b/kapeuka-haegsimgaideu-2nd_230501-pages-29-46.pdf
[11] Apache Kafka fundamentals - IBM Developer https://developer.ibm.com/articles/event-streams-kafka-fundamentals/
[12] Introduction to Apache Kafka [Tutorial] https://dzone.com/articles/introduction-to-apache-kafka-1
[13] Kafka Publish-Subscribe Model Explained | How Kafka Pub/Sub Works with Real Examples https://www.youtube.com/watch?v=mOTVqDHijwc
[14] Kotest: The Kotlin Testing Framework You Will Love - SoftwareMill https://softwaremill.com/kotest-the-kotlin-testing-framework-you-will-love/
[15] Apache Kafka https://en.wikipedia.org/wiki/Apache_Kafka
[16] Kafka producer and consumer written with Kotlin https://lankydan.dev/kafka-producer-and-consumer-written-with-kotlin/
[17] A Quick and Practical Example of Kafka Testing https://dzone.com/articles/a-quick-and-practical-example-of-kafka-testing
[18] 1 Introduction to Apache Kafka · Apache Kafka in Action https://livebook.manning.com/book/apache-kafka-in-action/chapter-1/v-5/
[19] Using Spring w/Kotlin to Produce/Consume Kafka Cloud Events https://www.confluent.io/blog/spring-kotlin-kafka-cloud-example/
[20] Introduction to Apache Kafka: Essential Guide for Beginners https://dev.to/elsayed85/introduction-to-apache-kafka-essential-guide-for-beginners-46g9
[21] Kafka Producer/Consumer 만들기 (feat. Kotlin) - Yebali - 티스토리 https://yebali.tistory.com/70
