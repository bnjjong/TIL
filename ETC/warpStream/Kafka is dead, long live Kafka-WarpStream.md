클라우드 환경에서 **Apache Kafka®의 높은 비용과 복잡한 운영 문제**로 고민하는 개발자라면 이 글에 주목해야 합니다. WarpStream은 기존 Kafka의 강력한 분산 로그 추상화는 유지하면서도, S3와 같은 **오브젝트 스토리지 기반으로 재설계**하여 클라우드 환경에 최적화된 데이터 스트리밍 플랫폼을 제시합니다. 이 콘텐츠를 통해 Kafka 운영에 드는 막대한 **인터-AZ 대역폭 비용과 엔지니어링 리소스**를 획기적으로 절감하고, 복잡한 클러스터 관리 부담에서 벗어나 비즈니스 문제 해결에 집중할 수 있는 실질적인 방법을 발견할 수 있습니다. 특히, 5-10배의 비용 절감 효과와 간소화된 운영 방식을 구체적인 데이터와 함께 제시하여, **클라우드 네이티브 스트리밍 아키텍처**로의 전환을 고민하는 이들에게 명확한 해답을 제공합니다.

## 1. WarpStream 소개: 클라우드 환경에 최적화된 Kafka 대체 솔루션

1. **WarpStream의 핵심 기능**: WarpStream은 S3 기반으로 구축된 Apache Kafka® 프로토콜 호환 데이터 스트리밍 플랫폼이다.  
    1. **기술적 특징**: 단일의 무상태(stateless) Go 바이너리로 제공되어 로컬 디스크 관리, 브로커 리밸런싱, ZooKeeper 운영이 필요 없다.  
    2. **비용 절감 효과**: 클라우드 환경에서 Kafka보다 5-10배 저렴하며, 이는 데이터 스트림이 인터-존(inter-zone) 네트워킹 대신 S3를 직접 사용하기 때문이다.  
        1. **Kafka 비용의 주요 원인**: 대규모 Kafka 배포 시 인프라 비용의 80% 이상이 인터-존 네트워킹 비용에서 발생한다.  

## 2. Kafka의 현재 문제점: 클라우드 환경과의 부적합성

1. **Kafka의 역사와 위상**: Apache Kafka®는 2011년 오픈소스화된 이후 스트리밍 아키텍처 구축의 표준 인프라가 되었다.  
    1. **분산 로그 추상화의 강력함**: Jay Kreps의 "The Log" 블로그 게시물에서 설명된 Kafka의 분산 로그 추상화는 매우 강력하다.  
2. **현대 소프트웨어 환경 변화와 Kafka의 한계**: 2011년 이후 클라우드 환경으로의 전환 등 많은 변화가 있었지만, Kafka는 거의 동일하게 유지되었다.  
    1. **클라우드 환경에서의 불만족**: 많은 조직이 Kafka를 클라우드 환경으로 "리프트 앤 시프트(lift and shift)"했지만, 결과에 만족하지 못하고 있다.  
    2. **Kafka 운영의 어려움**: Kafka는 대부분의 조직에게 비싸고, 까다로우며, 운영하기 어렵다.  
3. **Kafka가 현대 워크로드에 부적합한 두 가지 주요 이유**: Kafka 자체는 훌륭한 소프트웨어이지만, 2011년 LinkedIn 데이터 센터 환경에 적합하게 설계되어 현대 워크로드에는 맞지 않는다.  
    1. **클라우드 경제성 문제**: Kafka의 복제 전략은 막대한 인터-AZ(Availability Zone) 대역폭 비용을 발생시킨다.  
    2. **운영 오버헤드**: 자체 Kafka 클러스터를 운영하려면 전담 팀과 정교한 맞춤형 도구가 필요하다.  
4. **문제의 보편성**: 이 글에서 Kafka에 대해 언급하는 모든 내용은 로컬 디스크에 데이터를 저장하는 유사한 시스템(프로그래밍 언어 무관)에도 동일하게 적용된다.  

## 2.1. Kafka의 경제성 문제 (Kafka-nomics)

1. **일반적인 Kafka 클러스터의 비용 구조**: 3개 가용성 존(AZ)으로 구성된 Kafka 클러스터에서 데이터가 생산될 때마다 2/3의 확률로 존 간 전송이 발생하며, 내구성 및 가용성을 위해 파티션 리더가 다른 두 존의 팔로워에게 데이터를 복제한다.  
    1. **존 간 데이터 전송 비용**: 1GiB의 데이터가 존 간 전송될 때마다 $0.02의 비용이 발생한다 (송신 존에서 $0.01, 수신 존에서 $0.01).  
    2. **최적 시나리오에서의 GiB당 비용**: Kafka 클러스터를 통해 스트리밍되는 모든 GiB 데이터당 $0.053의 비용이 발생한다.  
    3. **S3 스토리지 비용과의 비교**: S3에 1GiB 데이터를 한 달간 저장하는 비용은 $0.021로, Kafka를 통해 데이터를 복사하는 비용으로 S3에 두 달 이상 데이터를 저장할 수 있다.  
2. **대규모 Kafka 워크로드의 비용 구성**: 처리량이 상당한 Kafka 클러스터의 경우, 하드웨어 비용은 무시할 수 있으며, 워크로드 비용의 70-90%는 존 간 대역폭 요금이다.  
    1. **Confluent의 분석**: Confluent도 이 문제에 대해 잘 설명하고 있다.  
3. **인터-AZ 대역폭 문제의 근본적인 원인**: 이 문제는 Kafka의 작동 방식에 근본적이다.  
    1. **설계 당시 환경**: Kafka는 LinkedIn의 데이터 센터에서 실행되도록 설계되었으며, 당시 네트워크 엔지니어는 애플리케이션 개발자에게 데이터 이동 비용을 청구하지 않았다.  
    2. **현재 운영 환경**: 오늘날 대부분의 Kafka 사용자는 퍼블릭 클라우드에서 Kafka를 실행하며, 이는 완전히 다른 제약 조건과 비용 모델을 가진 환경이다.  
    3. **비용 회피의 어려움**: 조직이 연간 수천만 또는 수억 달러의 클라우드 지출을 감당할 수 없다면, 이 문제의 물리적 한계를 피할 수 없다.  
4. **스토리지 요구 사항 문제**: 처리량이 낮더라도 장기 보존이 필요한 Kafka 클러스터는 대규모 스토리지 요구 사항을 가질 수 있다.  
    1. **로컬 SSD 복제 비용**: Kafka가 고가의 로컬 SSD에 데이터를 3중 복제하는 방식은 S3와 같은 오브젝트 스토리지를 사용하는 것보다 GiB당 약 10-20배 더 비싸다 (최적의 디스크 활용률 100% 가정 시).  

## 2.2. Kafka의 운영 오버헤드 문제 (Accidental SRE)

1. **개발자들이 Kafka를 접하는 이유**: 대부분의 개발자는 실제 문제를 해결하기 위해 Apache Kafka®를 처음 접한다.  
    1. **문제 해결 전 학습해야 할 내용**: 그러나 문제를 해결하기 전에 Kafka(브로커, 코디네이터, 워터마크 등), ZooKeeper(또는 KRaft), 리더 선출, 파티션(개수, 변경 불가), 컨슈머 그룹, 리밸런싱, 브로커 튜닝, 클라이언트 튜닝 등 수많은 개념을 학습해야 한다.  
2. **Kafka 클러스터 관리의 복잡성**: Kafka의 "데이터 플레인"(브로커)과 합의 기반 "컨트롤 플레인"(컨트롤러, ZooKeeper 등)은 모두 로컬 SSD에서 직접 실행되며, 전문 지식과 주의 깊은 관리가 필요하다.  
    1. **전담 팀 및 맞춤형 도구 필요**: 자체 호스팅 Kafka 클러스터는 노드 교체 및 클러스터 스케일링과 같은 기본적인 작업도 안전하고 안정적으로 수행하기 위해 전담 전문가 팀과 상당한 양의 맞춤형 도구가 필요하다.  
    2. **파티션 재할당 도구의 한계**: Apache Kafka에 내장된 파티션 재할당 도구는 하드웨어 장애 발생 시 브로커 해제를 위한 계획을 자동으로 생성할 수 없다.  
        1. **수동 작업의 필요성**: 관리자는 해제될 브로커의 모든 파티션 복제본을 나머지 브로커로 이동시키는 재할당 계획을 수동으로 수립해야 하며, 이때 모든 복제본이 단일 브로커로 이동되지 않도록 주의해야 한다.  
3. **호스팅 제공업체 사용의 한계**: AWS MSK와 같은 호스팅 제공업체에 클러스터 관리를 위임해도 운영 부담 문제가 완전히 해결되지 않는다.  
    1. **MSK의 클러스터 리밸런싱 문서**: MSK의 클러스터 리밸런싱(매우 일상적인 작업) 문서조차 Apache Kafka 문서로 연결되며, 이는 JSON을 수동으로 편집하여 어떤 파티션을 어떤 브로커로 마이그레이션할지 지정해야 한다.  
    2. **자동화 부족**: 파티션 재할당 도구는 Kafka 클러스터의 데이터 분포를 자동으로 분석하고 파티션을 이동하여 균등한 로드 분배를 달성하는 기능이 없다.  
4. **오픈소스 솔루션의 추가 부담**: Cruise Control과 같은 오픈소스 솔루션이 부담을 덜어줄 수 있지만, 이는 또 다른 개념 학습, 서비스 배포 및 모니터링, 그리고 예상치 못한 문제에 대한 대처를 요구한다.  
    1. **Cruise Control의 복잡성**: Cruise Control 자체는 Apache Kafka와 ZooKeeper에 의존하는 JVM 애플리케이션으로, 결코 가벼운 솔루션이 아니다.  
5. **결론**: 많은 경우 개발자들은 비즈니스 문제를 해결하려다가 결국 Kafka SRE가 되는 상황에 처한다.  

## 3. S3 기반 아키텍처의 필요성

1. **Kafka 사용의 제약**: Apache Kafka®의 높은 비용(금전적, 엔지니어링 시간) 때문에 오늘날 기업들은 사기 탐지 및 CDC(Change Data Capture)와 같은 가장 가치 있는 사용 사례에만 Kafka를 사용할 여유가 있다.  
    1. **높은 진입 장벽**: 다른 어떤 용도로든 Kafka를 사용하는 데 드는 비용은 너무 높다.  
2. **Datadog의 Husky 사례**: Datadog에서 S3 기반으로 구축된 관측 가능성 데이터용 컬럼형 데이터베이스인 Husky를 개발했다.  
    1. **Husky의 장점**: Husky는 무상태(mostly stateless) 및 자동 스케일링되는 데이터 레이크로, 매우 비용 효율적이고, 디스크 공간이 부족할 일이 없으며, 운영이 간단했다.  
    2. **Kafka 클러스터와의 비교**: Husky 개발 후, 기존 Kafka 클러스터는 상대적으로 "구식"으로 보였다.  
3. **Datadog의 Kafka 인프라 규모**: Datadog의 Kafka 대역폭은 수십 GiB/s에 달했고, 브로커 스토리지는 수 PiB의 NVMe로 측정되었다.  
    1. **오픈소스 Kafka 운영의 어려움**: 오픈소스 Kafka, 맞춤형 도구, 베어 메탈 VM을 사용하여 이러한 수준의 인프라를 유지하는 것은 결코 쉬운 일이 아니었다.  
    2. **S3 시스템과의 경쟁 불가**: Datadog의 유능한 엔지니어링 팀 덕분에 운영이 가능했지만, 수년간의 투자에도 불구하고 S3와 같은 시스템의 견고성, 확장성, 비용 효율성, 탄력성을 따라잡을 수 없었다.  
4. **오브젝트 스토리지의 이점**: 일반적으로 클라우드 환경에서 대규모 스토리지 워크로드는 오브젝트 스토리지의 경제성, 신뢰성, 확장성, 탄력성과 경쟁할 수 없다.  
    1. **빅데이터 기술의 오브젝트 스토리지 활용**: Snowflake, Databricks와 같은 "빅데이터" 기술은 이러한 이유로 오브젝트 스토리지 중심으로 시스템을 설계한다.  
5. **Kafka의 한계 극복의 필요성**: Uber, Datadog 등 많은 기업이 Kafka의 단점에도 불구하고 이를 활용하고 있지만, 기존 Kafka 구현이 진입 장벽으로 남아있다면 해결되지 않을 흥미로운 문제들이 너무 많다.  
    1. **WarpStream의 목표**: 데이터 스트리밍 인프라를 S3만큼 접근하기 쉽게 만드는 것을 목표로 한다.  
6. **S3 기반 Kafka 시스템의 잠재적 이점**: S3 위에 Kafka와 유사한 시스템을 구축하면 Kafka의 두 가지 주요 문제(비용 및 운영 오버헤드)를 한 번에 해결할 수 있다.  
    1. **비용 절감**: 주요 클라우드 제공업체는 VM과 오브젝트 스토리지 간의 네트워킹 비용을 청구하지 않는다.  
    2. **운영 부담 해소**: AWS는 S3가 안정적으로 실행되고 무한히 확장되도록 수백 명의 엔지니어를 고용하고 있어, 사용자가 직접 관리할 필요가 없다.  
7. **S3 기반 시스템 구축의 어려움**: S3와 같은 고지연 스토리지 매체 위에 Kafka 프로토콜의 모든 의미론을 제공하면서 로컬 디스크 없이 저지연 스트리밍 인프라를 구축하는 것은 매우 어려운 문제이다.  
8. **WarpStream의 질문**: "오늘날 현대 클라우드 환경에서 오브젝트 스토리지 위에 직접 실행되고, 로컬 디스크 관리 없이 기존 Kafka 프로토콜을 지원하도록 Kafka를 처음부터 재설계한다면 어떤 모습일까?"  
    1. **WarpStream의 답변**: WarpStream은 이 질문에 대한 답변이다.  

## 4. WarpStream 아키텍처 소개

1. **WarpStream의 정의**: WarpStream은 Apache Kafka® 프로토콜 호환 데이터 스트리밍 플랫폼으로, AWS S3, GCP GCS, Azure Blob Storage 등 모든 상용 오브젝트 스토어 위에서 직접 실행된다.  
    1. **주요 특징**: 인터-AZ 대역폭 비용이 전혀 발생하지 않고, 관리할 로컬 디스크가 없으며, VPC 내에서 완전히 실행될 수 있다.  
2. **WarpStream 아키텍처의 핵심 요소**: WarpStream은 Kafka 브로커 대신 "에이전트(Agents)"를 사용한다.  
    1. **에이전트의 특징**: 에이전트는 무상태(stateless) Go 바이너리(JVM 없음)로 Kafka 프로토콜을 사용한다.  
    2. **에이전트의 역할**: 기존 Kafka 브로커와 달리 모든 WarpStream 에이전트는 모든 토픽의 "리더" 역할을 할 수 있고, 모든 컨슈머 그룹의 오프셋을 커밋할 수 있으며, 클러스터의 코디네이터 역할을 할 수 있다.  
    3. **자동 스케일링의 용이성**: 어떤 에이전트도 특별하지 않으므로, CPU 사용량이나 네트워크 대역폭에 따라 에이전트를 자동 스케일링하는 것이 간단하다.  
3. **Kafka의 복잡성 해결 방법**: Apache Kafka가 Apache ZooKeeper(또는 KRaft)와 로컬 SSD 및 복제를 사용하는 상태 저장 브로커를 필요로 하는 문제를 WarpStream은 다음과 같이 해결한다.  
    1. **스토리지와 컴퓨팅 분리**: 데이터를 S3로 오프로드하여 스토리지와 컴퓨팅을 분리한다.  
    2. **데이터와 메타데이터 분리**: 메타데이터를 맞춤형 메타데이터 스토어로 오프로드하여 데이터와 메타데이터를 분리한다.  
4. **오브젝트 스토리지로의 스토리지 오프로드의 이점**: S3와 같은 오브젝트 스토리지로 모든 스토리지를 오프로드하면 다음과 같은 이점이 있다.  
    1. **쉬운 에이전트 스케일링**: 로드 변화에 따라 WarpStream 에이전트 수를 쉽게 스케일링할 수 있으며, 데이터 리밸런싱이 전혀 필요 없다.  
    2. **빠른 장애 복구**: 어떤 요청이든 다른 에이전트에서 즉시 재시도할 수 있어 장애 복구가 빠르다.  
    3. **핫스팟 제거**: 각 파티션의 데이터 불균형으로 인해 일부 Kafka 브로커의 로드가 훨씬 높아지는 핫스팟 문제가 대부분 제거된다.  
    4. **운영 간소화**: 파티션을 수동으로 리밸런싱할 필요가 없으며, Cruise Control과 같은 복잡한 솔루션을 학습할 필요가 없다.  
5. **데이터와 메타데이터 분리의 이점**: WarpStream 설계의 또 다른 핵심은 현대 데이터 레이크처럼 데이터와 메타데이터를 분리하는 것이다.  
    1. **맞춤형 메타데이터 데이터베이스**: 모든 WarpStream "가상 클러스터"의 메타데이터는 이 문제를 가장 효율적이고 비용 효과적인 방식으로 해결하기 위해 처음부터 작성된 맞춤형 메타데이터 데이터베이스에 저장된다.  
    2. **무료 가상 클러스터 호스팅**: WarpStream은 메타데이터 스토어의 효율성에 대한 자신감으로 WarpStream 가상 클러스터를 무료로 호스팅한다.  
6. **WarpStream 아키텍처 요약**: WarpStream은 데이터 복제, 내구성, 가용성과 같은 어려운 문제들을 오브젝트 스토리지 버킷으로 오프로드하여 사용자가 이에 대해 신경 쓸 필요가 없게 한다.  
    1. **데이터 주권 유지**: 모든 데이터는 사용자의 클라우드 계정 내에 유지된다.  
    2. **클라우드 계정을 벗어나는 데이터**: WarpStream을 통해 클라우드 계정을 벗어나는 유일한 데이터는 합의에 필요한 워크로드 메타데이터(예: 파티션 내 배치 순서)이다.  
7. **현대 데이터 스트리밍 파이프라인의 문제점**: 오늘날 대규모 데이터 스트리밍 파이프라인을 인프라에 도입하려는 현대 실무자들은 좋은 선택지가 많지 않다.  
    1. **기존 선택지**: Kafka 운영을 위한 전담 엔지니어 팀을 구성하거나, 호스팅 솔루션에 더 많은 비용을 지불해야 하므로 많은 스트리밍 사용 사례가 경제적으로 불가능해진다.  
8. **WarpStream의 비전**: WarpStream은 클라우드를 약점이 아닌 강점으로 활용하여 데이터 스트리밍 세계에서 새로운 가능성을 열어주는 더 나은 옵션을 제공할 수 있다고 생각한다.  

## 5. WarpStream의 비용 효율성 및 성능 검증

1. **인터-존 네트워킹 비용 절감 효과**: WarpStream은 테스트 환경에서 지속적으로 140MiB/s의 데이터를 생산하고 3개의 전용 컨슈머로 소비하여 총 560MiB/s의 지속적인 데이터 전송 워크로드를 실행한다.  
    1. **WarpStream의 일일 비용**: WarpStream은 일일 평균 $15 미만의 인터-존 네트워킹 비용을 발생시킨다.  
    2. **Kafka의 예상 일일 비용**: 동일한 워크로드를 Kafka 클러스터로 실행할 경우, 인터-존 네트워킹 비용만으로 하루에 $641이 발생할 것으로 예상된다.  
2. **S3 API 운영 비용**: WarpStream은 이러한 인터-존 네트워킹 비용을 하드웨어 또는 S3 API 비용으로 대체하지 않는다.  
    1. **S3 API 운영 비용**: 동일한 워크로드에 대한 S3 API 운영 비용은 하루에 $40 미만이다.  
3. **하드웨어 요구 사항**: WarpStream은 27 vCPU에 해당하는 에이전트 하드웨어/VM만 필요하다.  
4. **총 소유 비용 (TCO) 절감**: WarpStream은 대부분의 Kafka 워크로드 비용을 5-10배 절감할 수 있다.  
    1. **1GiB/s Kafka 워크로드 비교**: 지속적인 1GiB/s Kafka 워크로드와 WarpStream의 비용을 비교한 결과, WarpStream이 훨씬 저렴하다.  
    2. **Kafka 비용의 주요 원인**: 고용량 Kafka 워크로드의 경우 하드웨어 비용은 무시할 수 있으며, 워크로드 비용은 인터-존 네트워킹 요금에 의해 지배된다.  
    3. **WarpStream의 장점**: WarpStream은 이러한 네트워킹 요금을 완전히 제거한다.  
    4. **참고 사항**: 이 비교는 Kafka 클러스터가 컨슈머의 인터-존 네트워킹 비용을 줄이기 위해 팔로워 페치(follower fetch) 기능을 사용하도록 올바르게 구성된 최적의 시나리오를 가정한 것이다.  
        1. **추가 비용**: 팔로워 페치 기능이 구성되지 않은 경우 Kafka 비용은 훨씬 높아질 수 있으며, 자체 호스팅 Kafka 설정의 엔지니어 급여 비용은 제외되었다.  
5. **WarpStream의 트레이드오프: 지연 시간**: WarpStream은 지연 시간 측면에서 트레이드오프를 가진다.  
    1. **Produce 요청 P99 지연 시간**: 현재 구현에서 Produce 요청의 P99 지연 시간은 약 400ms이다.  
        1. **지연 시간의 원인**: 데이터가 S3에 영구적으로 저장되고 클라우드 컨트롤 플레인에 커밋될 때까지 확인(acknowledge)하지 않기 때문이다.  
    2. **엔드-투-엔드 P99 지연 시간**: 프로듀서에서 컨슈머까지의 데이터 엔드-투-엔드 P99 지연 시간은 약 1초이다.  
6. **WarpStream의 가치 제안**: 워크로드가 프로듀서-컨슈머 지연 시간 P99 약 1초를 허용할 수 있다면, WarpStream은 총 데이터 스트리밍 비용을 GiB당 5-10배 절감할 수 있으며, 운영 오버헤드가 거의 없다.  
    1. **벤더 종속성 없음**: 독점적인 인터페이스가 아닌 Kafka 프로토콜을 사용하므로 벤더 종속성이 없다.  
    2. **다양한 클라우드 환경 지원**: AWS의 S3, GCP의 GCS, Azure의 Azure Blob Storage 등 오브젝트 스토어 구현이 있는 모든 환경에서 실행될 수 있다.  

## 6. Kafka의 세 번째 문제점: 개발자 UX 및 WarpStream의 미래 방향

1. **WarpStream이 해결하는 주요 문제**: WarpStream은 Kafka의 두 가지 주요 문제인 클라우드 경제성과 운영 오버헤드를 해결한다.  
2. **Kafka의 세 번째 문제점**: Kafka의 세 번째 주요 문제는 개발자 UX(사용자 경험)이다.  
    1. **파티션 추상화의 한계**: 파티션은 비 trivial한 스트림 처리 애플리케이션을 작성하기에는 너무 낮은 수준의 추상화이다.  
    2. **WarpStream의 잠재력**: WarpStream의 아키텍처는 개발자들이 기존 애플리케이션을 작성하는 방식에 훨씬 가까운 새로운 방식으로 스트림 처리 애플리케이션을 작성하도록 돕는 독특한 위치에 있다.  
3. **향후 계획**: 이 내용은 향후 블로그 게시물에서 더 자세히 다룰 예정이다.  
    1. **현재 목표**: 개발자들이 이미 익숙한 도구의 개선된 버전을 제공하여 개발자들의 현재 요구를 충족시키는 것이 첫 번째 목표이다.